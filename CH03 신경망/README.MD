# 신경망

- 신경망의 표현 2가지
<br>
입력 - 은닉층 1층 - 출력층으로 이루어진 신경망이 있을 때 <br>
1. 신경망의 층을 기준으로 3층 신경망이라고 표현
2. 가중치 층이 2층이므로 2층 신경망이라고 표현

## bias와 활성화 함수가 적용된 신경망 구조도

> 사진넣어라.
> 

h() : 활성화함수. 가중치와 입력데이터의 곱을 다음 노드로 넘겨줄지 아닐지를 결정하는 임계치의 기준을 가지고 있음.

> 명심할 점
> 
> 은닉층 노드안에 `입력데이터*가중치 합`노드와 출력층 노드로 이루어져 있으며, 이 두 노드는 활성화 함수 activation function으로 연결되어 있다.
> 

## 활성화 함수 종류

### sigmoid
y = 1/(1+exp(-x))

###### 넘파이 브로드캐스트 기능
넘파이 배열과 스칼라 값의 연산을 넘파이 배열의 원소 각각과 스칼라 값의 연산으로 바꿔 수행하는 것

###### 배열의 크기뽑기

A = np.array([1, 2, 3, 4])일 때 <br>

- np.ndim(A) : 1 : 배열의 차원 수
- A.shape : (4,) : 배열의 형상, 튜플형식
    - (4,) : [1, 2, 3, 4]
    - (4,1): [ [1, 2, 3, 4] ]
- A.shape[0] : 4 : 

### relu

### leakyRelu

### tanh

### softmax 

###
