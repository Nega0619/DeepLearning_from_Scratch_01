## 1. 전체구조

- Affine 계층 구조
  - 이제껏 본 신경망으로, 완전 연결 신경망 Fully connected 신경망이라고도 합니다.
  - 신경망이 인접하는 계층의 모든 뉴런과 결합되어 있는 형태
  - 예시 : input - \[Affine - relu\] - \[Affine - relu\] - \[Affine - relu\] - \[Affine - relu\] - \[Affine - softmax\] - output

 .

- Conv 구조
  - input - \[conv - relu - pooling\] - \[conv - relu - pooling\] - \[conv - relu\] - \[Affine - relu\] - \[Affine - softmax\] - output
  - pooling층은 생략하기도 한다.
  - Affine계층 구조에서 사용한 것과 동일한 Affine-relu나 Affine-softmax를 동일하게 사용할 수 있다.

## 2. 합성곱 계층

- 완전 연결 계층의 문제점 : 데이터 형상이 무시된다.
  - 이미지는 3차원인데도 불구하고 1차원으로 평탄화를 해주며, 이 과정에서 공간적 정보가 사라져 버린다.

- 합성곱의 장점 : 데이터 형상을 유지한다.
  - 합성곱 계층의 입 출력 데이터 : FEATURE MAP

### 합성곱 연산

합성곱 연산 = 필터 연산(이미지 처리)
- 필터 = 커널
- 입력데이터와 필터는 같은 차원의 데이터를 갖는다.
- 입력데이터에 필터와 곂쳐지는 부분을 윈도우라고 하며, 윈도우 값과 필터를 곱한 후 그 총합을 구합니다.(단일 곱셈-누산 fused multiply-add FMA)
- CNN의 필터의 매개변수 = 가중치, 편향도 존재한다.
  - 편향은 1\*1 1개만 존재  

패딩
- 합성곱 연산을 하기 전에 이미지 데이터 주변을 특정값으로 채우는 것(2나 3도 가능)
- 패딩을 사용함으로써 출력 데이터의 크기를 조정한다.

스트라이드
- 필터를 적용하는 위치의 간격

#### 출력크기 계산
입력크기 = (H, W), 필터크기(FH, HW), 출력 크기=(OH, OW), 패딩 P, 스트라이드 S일 때

OH = (H+2P-FH)/S + 1
OW = (W+2P-FW)/S + 1

출력크기는 무조건 정수여야 함. (데이터의 수니까요^^, BUT 딥러닝 프레임워크에는 값이 나누어 떨어지지 않을 경우 가장 가까운 정수로 반올림하는등 에러를 관리하기도 한다.)

### 3차원 데이터의 합성곱 계층
입력 데이터 채널 수 = 필터의 채널 수, H와 W는 달라도되며 조절 가능하다.

입력데이터 = 채널수 * H * W
필터 = 채널수 * FH * FW

( 입력데이터 * 필터(채널마다 수행) ) 결과를 다 더해서 1채널의 출력을 얻습니다.

**이는 FEATURE맵 1개를 의미합니다.**
